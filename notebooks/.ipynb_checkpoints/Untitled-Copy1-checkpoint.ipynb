{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-08-02T15:13:33.171957Z",
     "start_time": "2022-08-02T15:13:33.153460Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Graph with 0 nodes and 0 edges\n"
     ]
    }
   ],
   "source": [
    "graph = nx.Graph()\n",
    "print(graph)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-08-02T15:07:17.920427Z",
     "start_time": "2022-08-02T15:07:17.914441Z"
    }
   },
   "outputs": [],
   "source": [
    "# This is a trick taught by Jesús to include the directory containing the source \n",
    "# within the notebook scope\n",
    "import sys\n",
    "sys.path.append('../')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-08-02T18:44:37.072970Z",
     "start_time": "2022-08-02T18:44:35.939591Z"
    }
   },
   "outputs": [],
   "source": [
    "import networkx as nx\n",
    "import spacy \n",
    "from spacy.lang.es.examples import sentences\n",
    "import itertools as it\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from spacy.symbols import nsubj, VERB, root, ORTH, PUNCT\n",
    "\n",
    "MODEL = 'es_core_news_sm'\n",
    "MODEL = 'es_core_news_lg'\n",
    "\n",
    "# MODEL = 'en_core_web_md'\n",
    "# MODEL = 'es_core_news_lg'\n",
    "\n",
    "# we centralize the extraction\n",
    "nlp = spacy.load(MODEL)\n",
    "\n",
    "# Add special case rule\n",
    "special_case = [{ORTH: \"D/Dª\"}]\n",
    "nlp.tokenizer.add_special_case(\"D/Dª\", special_case)\n",
    "\n",
    "ruler = nlp.add_pipe(\"entity_ruler\")\n",
    "patterns = [ {\"label\": \"DNI\", \"pattern\": [{\"TEXT\": {\"REGEX\": \".*?[0-9]{8}[A-Z]\"}}]},\n",
    "             {\"label\": \"NUM\", \"pattern\": [{\"IS_DIGIT\":True}]}]\n",
    "ruler.add_patterns(patterns)\n",
    "\n",
    "\n",
    "def is_idx_part_of_entity(idx,dep_parse):\n",
    "    # print(f'is_idx: {idx} - {dep_parse[idx]}')\n",
    "    for i in range(len(dep_parse.ents)):\n",
    "        # print(f'ent: {dep_parse.ents[i].start} - {dep_parse.ents[i].end} : {[dep_parse[x] for x in range(dep_parse.ents[i].start, dep_parse.ents[i].end)]}')\n",
    "        if dep_parse.ents[i].start <= idx and idx <= dep_parse.ents[i].end:\n",
    "            return True\n",
    "    return False\n",
    "\n",
    "def build_graph_from_dependencies (doc): \n",
    "    edges = []\n",
    "    edge_labels = {}\n",
    "    roots = []\n",
    "    for token in doc:\n",
    "        if token.dep_=='ROOT': \n",
    "            roots.append(token)\n",
    "        for child in token.children:\n",
    "            edges.append(('{0}'.format(token.i),\n",
    "                          '{0}'.format(child.i)))\n",
    "            edge_labels [('{0}'.format(token.i),\n",
    "                          '{0}'.format(child.i)) ]= child.dep_\n",
    "    if len(roots) > 1: \n",
    "        # we have to reconstruct the graph -- maybe bad partitioning due to punctuation in our context\n",
    "        # This is completely heuristic as we are dealing with Spanish texts, we try to reconstruct the \n",
    "        # connectivity of the sentence by assuming local dependency \n",
    "        # if we don't see any punctuation nearby => we include a meta-root node\n",
    "        sorted_roots = sorted(roots, key=lambda x: x.i)\n",
    "        meta_roots = set()\n",
    "        meta_roots.add(sorted_roots[0])\n",
    "        sorted_roots.pop(0)\n",
    "        for crt_root in sorted_roots: \n",
    "            if crt_root.i-2 > 0: \n",
    "                if doc[crt_root.i-1].pos == PUNCT: \n",
    "                    print (f'{crt_root} - {doc[crt_root.i-2]}')\n",
    "                    edges.append(('{0}'.format(crt_root.i),\n",
    "                                  '{0}'.format(crt_root.i-2)))\n",
    "                    edge_labels [('{0}'.format(crt_root.i),\n",
    "                          '{0}'.format(crt_root.i-2)) ]= 'REC'\n",
    "                else: \n",
    "                    meta_roots.add(crt_root)\n",
    "            else: \n",
    "                meta_roots.add(crt_root)\n",
    "        if len(meta_roots) >1: \n",
    "            for crt_root in meta_roots: \n",
    "                edges.append(('-1','{0}'.format(crt_root.i)))\n",
    "                edge_labels [('-1','{0}'.format(crt_root.i)) ]= 'META_ROOT'\n",
    "        \n",
    "#     color_state_map = {'no_root': 'pink', 'root': 'red', 'meta_root': 'blue'}\n",
    "#     graph = nx.Graph()\n",
    "#     graph.add_edges_from(edges)\n",
    "#     states = ['meta_root' if node=='-1' else 'root' if doc[int(node)].dep_ == 'ROOT'  else 'no_root' for node in graph.nodes()]\n",
    "#     nx.set_node_attributes(graph, dict(zip(graph.nodes(), states)), 'state')\n",
    "#     node_labels = {n:doc[int(n)] for n in graph.nodes()}\n",
    "#     plt.figure(figsize=(10,10))\n",
    "#     pos = nx.spring_layout(graph, seed=225, )  # Seed for reproducible layout\n",
    "#     nx.draw(\n",
    "#         graph, pos, edge_color='black', width=1, linewidths=1, \n",
    "#         node_color=[color_state_map[node[1]['state']] for node in graph.nodes(data=True)], \n",
    "#         alpha=0.9,\n",
    "#         labels=node_labels\n",
    "#     )\n",
    "#     nx.draw_networkx_edge_labels(\n",
    "#         graph, pos, edge_labels=edge_labels,\n",
    "#         font_color='red'\n",
    "#     )\n",
    "#     plt.show()\n",
    "    return graph\n",
    "\n",
    "def check_path_crossing_another_entity (doc, path): \n",
    "    return any([ ent.start<= int(idx) and str(idx)<ent.end for idx in path for ent in doc.ents ])\n",
    "    \n",
    "\n",
    "def shortest_dependency_path(graph, e1=None, e2=None):\n",
    "    ## CB: This should also work for NERs, if the dep parsing is pointing at the\n",
    "    ## head of the entity,\n",
    "    ## However, the NE would not be added completely\n",
    "    shortest_path = []\n",
    "    try:\n",
    "        # print (f'looking shortest path from {e1.i} to {e2.i}')\n",
    "        shortest_path = nx.shortest_path(graph, source=str(e1.i), target=str(e2.i))\n",
    "    except nx.NetworkXNoPath:\n",
    "        print (f'problems with shortest_path - {str(e1.i)} {doc[e1.i]} - {str(e2.i)} {doc[e2.i]}')\n",
    "        print (graph)\n",
    "        shortest_path=[]\n",
    "    return shortest_path\n",
    "\n",
    "\n",
    "def obtain_children(idx, doc):\n",
    "    to_process = [c for c in doc[idx].children]\n",
    "    children=[]\n",
    "    while len(to_process) != 0:\n",
    "        c = to_process.pop()\n",
    "        children.append(c.i)\n",
    "        for child in c.children:\n",
    "            if child.idx not in children:\n",
    "                to_process.append(child)\n",
    "\n",
    "    return sorted(children)  \n",
    "\n",
    "def add_children_deps(path, dep_parse):\n",
    "    children_start = obtain_children(int(path[0]), dep_parse)\n",
    "    children_end = obtain_children(int(path[-1]), dep_parse)\n",
    "    added_children = [x for x in (children_start + children_end) if int(path[0]) <= int(x) and int(x) <= int(path[-1]) and not is_idx_part_of_entity(int(x), dep_parse)]\n",
    "    test = [int(x) for x in (path + added_children)]\n",
    "    if int(path[0]) < int(path[-1]):\n",
    "        return sorted([int(x) for x in test])\n",
    "    else:\n",
    "        return sorted([int(x) for x in test],reverse=True)\n",
    "\n",
    "def generate_textual_patterns_with_pos_tags(corpus, extend_children=False, force_entities=False):\n",
    "    \"\"\"A method to generate textual patterns given the corpus.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    corpus : type List\n",
    "        List of sentences is passed.\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    type List\n",
    "        List of textual patterns\n",
    "\n",
    "    \"\"\"\n",
    "\n",
    "    patterns_pos_tags = []\n",
    "    textual_patterns = []\n",
    "    for i, sentence in enumerate(corpus):\n",
    "        dep_parse = nlp(sentence)\n",
    "        graph = build_graph_from_dependencies(dep_parse)\n",
    "        try:\n",
    "            if len(dep_parse.ents) == 2:\n",
    "                path = shortest_dependency_path(graph, dep_parse[dep_parse.ents[0].start], dep_parse[dep_parse.ents[1].start])\n",
    "                if len(path) != 2:\n",
    "                    if (extend_children):\n",
    "                        path = add_children_deps(path, dep_parse)\n",
    "                    else:\n",
    "                        path = [int (x) for x in path]\n",
    "                    # print (f'path: {path}')\n",
    "                    ## we add the entity and its POS in parallel\n",
    "                    shortest_path = dep_parse.ents[0].label_+'_<'+str(dep_parse[dep_parse.ents[0].start:dep_parse.ents[0].end]) + '> '\n",
    "                    pos_tags = ['<'+dep_parse.ents[0].label_+'>']\n",
    "                    ## we add all the words in the middle in the same order\n",
    "                    shortest_path += ' '.join([dep_parse[j].text for j in path[1:-1]])\n",
    "                    for j in path[1:-1]:\n",
    "                        pos_tags.append(dep_parse[j].pos_)\n",
    "                    ## and now the last entity\n",
    "                    shortest_path += ' '+dep_parse.ents[1].label_+'_<'+str(dep_parse[dep_parse.ents[1].start:dep_parse.ents[1].end]) + '> '\n",
    "                    pos_tags.append('<'+dep_parse.ents[1].label_+'>')\n",
    "                    # TODO: update the way of extending with advmod (not yet)\n",
    "                    # textual_patterns.append(adv_mod_deps(shortest_path, dep_parse))\n",
    "                    textual_patterns.append(shortest_path)\n",
    "                    patterns_pos_tags.append(pos_tags)\n",
    "            elif len(dep_parse.ents)> 2:\n",
    "                pairs = it.combinations(dep_parse.ents, 2)\n",
    "                for pair in pairs:\n",
    "                    path = shortest_dependency_path(graph, dep_parse[pair[0].start], dep_parse[pair[1].start])  \n",
    "                    if not(force_entities and check_path_crossing_another_entity(doc,path)): \n",
    "                        if len(path) != 2:\n",
    "                            if (extend_children):\n",
    "                                path = add_children_deps(path, dep_parse)\n",
    "                            else:\n",
    "                                path = [int(x) for x in path]\n",
    "                            # print(f'path: {path}')\n",
    "                            shortest_path = pair[0].label_+'_<'+ str(dep_parse[pair[0].start:pair[0].end]) + '> '\n",
    "                            pos_tags = ['<' + pair[0].label_ + '>']\n",
    "                            shortest_path += ' '.join([dep_parse[j].text for j in path[1:-1]])\n",
    "                            for j in path[1:-1]:\n",
    "                                pos_tags.append(dep_parse[j].pos_)\n",
    "                            shortest_path += ' '+pair[1].label_+'_<'+str(dep_parse[pair[1].start:pair[1].end])+'> '\n",
    "                            pos_tags.append('<' + pair[1].label_ + '>')\n",
    "                            # TODO: update this\n",
    "                            # textual_patterns.append(adv_mod_deps(shortest_path, dep_parse))\n",
    "                            textual_patterns.append(shortest_path)\n",
    "                            patterns_pos_tags.append(pos_tags)\n",
    "        except Exception as e:\n",
    "            print (e)\n",
    "            pass\n",
    "    return textual_patterns, patterns_pos_tags\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 176,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-08-02T18:47:11.353089Z",
     "start_time": "2022-08-02T18:47:11.250635Z"
    },
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Apple está buscando comprar una startup del Reino Unido por mil millones de dólares.\n",
      "Either source 0 or target 7 is not in G\n",
      "Los coches autónomos delegan la responsabilidad del seguro en sus fabricantes.\n",
      "San Francisco analiza prohibir los robots de reparto.\n",
      "Londres es una gran ciudad del Reino Unido.\n",
      "Either source 0 or target 6 is not in G\n",
      "El gato come pescado.\n",
      "Veo al hombre con el telescopio.\n",
      "La araña come moscas.\n",
      "El pingüino incuba en su nido sobre el hielo.\n",
      "¿Dónde estáis?\n",
      "¿Quién es el presidente francés?\n",
      "¿Dónde se encuentra la capital de Argentina?\n",
      "Either source 0 or target 7 is not in G\n",
      "¿Cuándo nació José de San Martín?\n",
      "Either source 0 or target 3 is not in G\n",
      "En cumplimiento de lo estipulado en la Ley Orgánica 15/1999 de 13 de diciembre, de Protección de Datos de Carácter Personal(Disposición Transitoria Cuarta. L. O 3/2018 de Protección de Datos Personales\n",
      "L. - Cuarta\n",
      "Either source 7 or target 11 is not in G\n",
      "ACTA DE INFORMACIÓN DE DERECHOS A LA VÍCTIMA DE DELITO En MALAGA-ODAC CENTRAL (MALAGA), siendo las 00 horas 31 minutos del día 04 de enero de 2020 por el funcionario del Cuerpo Nacional de Policía con carnet profesional número 95347 se procede a informar a D/Dª Sandra GOMEZ ROMERO, con DNI nº 74826416X, con domicilio en Calle Corregidor Calos Garcia Garafa 1, Bq 10, 7b , de Malaga , teléfono/móvil 952329622 , conforme a lo dispuesto en la Ley 4/2015, del Estatuto de la Víctima y la Ley de Enjuiciamiento Criminal (artículos 109, 109 bis, 110 y 771.1ª):En su condición de víctima.\n",
      "Either source 2 or target 14 is not in G\n",
      "size: 0\n",
      "Done. \n"
     ]
    }
   ],
   "source": [
    "sents = []\n",
    "for s in sentences:\n",
    "    sents.append(s)\n",
    "sents.append('En cumplimiento de lo estipulado en la Ley Orgánica 15/1999 de 13 de diciembre, de Protección de Datos de Carácter Personal(Disposición Transitoria Cuarta. L. O 3/2018 de Protección de Datos Personales')\n",
    "sents.append('ACTA DE INFORMACIÓN DE DERECHOS A LA VÍCTIMA DE DELITO En MALAGA-ODAC CENTRAL (MALAGA), siendo las 00 horas 31 minutos del día 04 de enero de 2020 por el funcionario del Cuerpo Nacional de Policía con carnet profesional número 95347 se procede a informar a D/Dª Sandra GOMEZ ROMERO, con DNI nº 74826416X, con domicilio en Calle Corregidor Calos Garcia Garafa 1, Bq 10, 7b , de Malaga , teléfono/móvil 952329622 , conforme a lo dispuesto en la Ley 4/2015, del Estatuto de la Víctima y la Ley de Enjuiciamiento Criminal (artículos 109, 109 bis, 110 y 771.1ª):En su condición de víctima.')\n",
    "textual_patterns, post = generate_textual_patterns_with_pos_tags(sents, True, False)\n",
    "print(f'size: {len(textual_patterns)}')\n",
    "# textual_patterns, post = generate_textual_patterns_with_pos_tags(sents, True, False)\n",
    "# print(f'size: {len(textual_patterns)}')\n",
    "print (f'Done. ')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-08-02T17:38:26.139602Z",
     "start_time": "2022-08-02T17:38:26.109766Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ACTA DE INFORMACIÓN DE DERECHOS A LA VÍCTIMA DE DELITO En MALAGA-ODAC CENTRAL (MALAGA), siendo las 00 horas 31 minutos del día 04 de enero de 2020 por el funcionario del Cuerpo Nacional de Policía con carnet profesional número 95347 se procede a informar a Dª Sandra GOMEZ ROMERO, con DNI nº 74826416X, con domicilio en Calle Corregidor Calos Garcia Garafa 1, Bq 10, 7b , de Malaga , teléfono/móvil 952329622 , conforme a lo dispuesto en la Ley 4/2015, del Estatuto de la Víctima y la Ley de Enjuiciamiento Criminal (artículos 109, 109 bis, 110 y 771.1ª):En su condición de víctima."
      ]
     },
     "execution_count": 134,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "doc = nlp(sents[-1])\n",
    "doc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-08-02T17:38:26.171424Z",
     "start_time": "2022-08-02T17:38:26.141164Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<generator at 0x1c78e846ea8>"
      ]
     },
     "execution_count": 135,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "doc[0].children"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-08-02T16:31:14.261840Z",
     "start_time": "2022-08-02T16:31:14.233475Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFORMACIÓN - ACTA - nmod\n",
      "VÍCTIMA - ACTA - nmod\n",
      "MALAGA-ODAC - ACTA - obl\n"
     ]
    }
   ],
   "source": [
    "for child in doc[0].children: \n",
    "    print (f'{child} - {child.head} - {child.dep_}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "rdf2vecEnv",
   "language": "python",
   "name": "rdf2vecenv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
